{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import chainer\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from chainer import cuda, Function, Variable, optimizers, serializers, utils, initializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "from distill import DistillPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'backup/'\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mnist dataset and create data iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train num:60000, test num:10000\n"
     ]
    }
   ],
   "source": [
    "n_cls = 10\n",
    "train_num = len(train)\n",
    "test_num = len(test)\n",
    "print('train num:%d, test num:%d' % (train_num, test_num))\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, 256)\n",
    "test_iter = chainer.iterators.SerialIterator(test, 1000, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define teacher and student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class teacherNet(Chain):\n",
    "    def __init__(self):\n",
    "        super(teacherNet, self).__init__(\n",
    "            fc1 = L.Linear(28 * 28, 800),\n",
    "            fc2 = L.Linear(800, 800),\n",
    "            fc3 = L.Linear(800, 10),\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class studentNet(Chain):\n",
    "    def __init__(self):\n",
    "        super(studentNet, self).__init__(\n",
    "            fc1 = L.Linear(28 * 28, 8),\n",
    "            fc2 = L.Linear(8, 8),\n",
    "            fc3 = L.Linear(8, 10),\n",
    "        )\n",
    "    def __call__(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_iter, test_iter, max_iters, out_dir, out_name):\n",
    "    ts = time.strftime(\"%Y%m%d%H%M\",time.localtime())\n",
    "    model.predictor.train = True\n",
    "    cuda.get_device(0).use()\n",
    "    model.to_gpu()\n",
    "    # begin training\n",
    "    for iters in range(max_iters):\n",
    "        model.predictor.train = True\n",
    "        batch = train_iter.next()\n",
    "        x_data = np.array([x[0] for x in batch])\n",
    "        t = np.array([x[1] for x in batch])\n",
    "        x_data = Variable(x_data)\n",
    "        t = Variable(t)\n",
    "        x_data.to_gpu()\n",
    "        t.to_gpu()\n",
    "        loss = model(x_data,t)\n",
    "        accuracy = F.accuracy(model.predictor(x_data), t)\n",
    "        optimizer.zero_grads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        if (iters + 1) % (max_iters // 2) ==0:\n",
    "            optimizer.lr *= 0.5\n",
    "        if (iters + 1) % (max_iters // 100) == 0:\n",
    "            test_accuracy = cal_accuracy(model, test_iter)\n",
    "            txt_log = 'Iteration:%d   Loss:%f   Training Accuracy:%f   Test Accuracy:%f' % (iters + 1, loss.data, accuracy.data, test_accuracy)\n",
    "            print(txt_log)\n",
    "            # write training logs\n",
    "            with open(os.path.join(out_dir, out_name + '_' + ts + '.csv'),'a') as f:\n",
    "                f.write('%d,%f,%f,%f\\n' % (iters + 1, loss.data, accuracy.data, test_accuracy))\n",
    "                f.close()\n",
    "    # save model            \n",
    "    serializers.save_hdf5(os.path.join(out_dir, out_name + '_' + ts + '.model'), model.predictor)\n",
    "    \n",
    "def cal_accuracy(model,test_iter):\n",
    "    model.predictor.train = False\n",
    "    acc = []\n",
    "    test_iter.reset()\n",
    "    for i,batch in enumerate(test_iter):\n",
    "        x_data = np.array([x[0] for x in batch])\n",
    "        t = np.array([x[1] for x in batch])\n",
    "        x_data = Variable(x_data)\n",
    "        t = Variable(t)\n",
    "        x_data.to_gpu()\n",
    "        t.to_gpu()\n",
    "        acc.append(F.accuracy(model.predictor(x_data),t).data)\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:50   Loss:1.915706   Training Accuracy:0.289062   Test Accuracy:0.315000\n",
      "Iteration:100   Loss:1.248915   Training Accuracy:0.527344   Test Accuracy:0.557100\n",
      "Iteration:150   Loss:0.868384   Training Accuracy:0.718750   Test Accuracy:0.710200\n",
      "Iteration:200   Loss:0.693116   Training Accuracy:0.789062   Test Accuracy:0.802400\n",
      "Iteration:250   Loss:0.708719   Training Accuracy:0.820312   Test Accuracy:0.837300\n",
      "Iteration:300   Loss:0.458827   Training Accuracy:0.875000   Test Accuracy:0.853300\n",
      "Iteration:350   Loss:0.532116   Training Accuracy:0.839844   Test Accuracy:0.867800\n",
      "Iteration:400   Loss:0.530561   Training Accuracy:0.867188   Test Accuracy:0.871000\n",
      "Iteration:450   Loss:0.522745   Training Accuracy:0.859375   Test Accuracy:0.876000\n",
      "Iteration:500   Loss:0.431409   Training Accuracy:0.863281   Test Accuracy:0.881700\n",
      "Iteration:550   Loss:0.366257   Training Accuracy:0.882812   Test Accuracy:0.882500\n",
      "Iteration:600   Loss:0.381890   Training Accuracy:0.875000   Test Accuracy:0.887600\n",
      "Iteration:650   Loss:0.403745   Training Accuracy:0.871094   Test Accuracy:0.887900\n",
      "Iteration:700   Loss:0.374130   Training Accuracy:0.894531   Test Accuracy:0.889700\n",
      "Iteration:750   Loss:0.401228   Training Accuracy:0.890625   Test Accuracy:0.891400\n",
      "Iteration:800   Loss:0.346575   Training Accuracy:0.878906   Test Accuracy:0.891700\n",
      "Iteration:850   Loss:0.317822   Training Accuracy:0.906250   Test Accuracy:0.895600\n",
      "Iteration:900   Loss:0.411785   Training Accuracy:0.894531   Test Accuracy:0.889600\n",
      "Iteration:950   Loss:0.409121   Training Accuracy:0.882812   Test Accuracy:0.895200\n",
      "Iteration:1000   Loss:0.445065   Training Accuracy:0.867188   Test Accuracy:0.894300\n",
      "Iteration:1050   Loss:0.321907   Training Accuracy:0.917969   Test Accuracy:0.895100\n",
      "Iteration:1100   Loss:0.270557   Training Accuracy:0.910156   Test Accuracy:0.897800\n",
      "Iteration:1150   Loss:0.372317   Training Accuracy:0.914062   Test Accuracy:0.894900\n",
      "Iteration:1200   Loss:0.302949   Training Accuracy:0.917969   Test Accuracy:0.894900\n",
      "Iteration:1250   Loss:0.409583   Training Accuracy:0.871094   Test Accuracy:0.895300\n",
      "Iteration:1300   Loss:0.302018   Training Accuracy:0.917969   Test Accuracy:0.893600\n",
      "Iteration:1350   Loss:0.414250   Training Accuracy:0.894531   Test Accuracy:0.901100\n",
      "Iteration:1400   Loss:0.341446   Training Accuracy:0.890625   Test Accuracy:0.899700\n",
      "Iteration:1450   Loss:0.418150   Training Accuracy:0.882812   Test Accuracy:0.900800\n",
      "Iteration:1500   Loss:0.422041   Training Accuracy:0.871094   Test Accuracy:0.900400\n",
      "Iteration:1550   Loss:0.497524   Training Accuracy:0.882812   Test Accuracy:0.899300\n",
      "Iteration:1600   Loss:0.375602   Training Accuracy:0.898438   Test Accuracy:0.900500\n",
      "Iteration:1650   Loss:0.287214   Training Accuracy:0.914062   Test Accuracy:0.900000\n",
      "Iteration:1700   Loss:0.286044   Training Accuracy:0.914062   Test Accuracy:0.902000\n",
      "Iteration:1750   Loss:0.414599   Training Accuracy:0.890625   Test Accuracy:0.895500\n",
      "Iteration:1800   Loss:0.379236   Training Accuracy:0.898438   Test Accuracy:0.900600\n",
      "Iteration:1850   Loss:0.381654   Training Accuracy:0.902344   Test Accuracy:0.900700\n",
      "Iteration:1900   Loss:0.321849   Training Accuracy:0.929688   Test Accuracy:0.905000\n",
      "Iteration:1950   Loss:0.354037   Training Accuracy:0.902344   Test Accuracy:0.901900\n",
      "Iteration:2000   Loss:0.298351   Training Accuracy:0.937500   Test Accuracy:0.906000\n",
      "Iteration:2050   Loss:0.344437   Training Accuracy:0.917969   Test Accuracy:0.898500\n",
      "Iteration:2100   Loss:0.398756   Training Accuracy:0.898438   Test Accuracy:0.902700\n",
      "Iteration:2150   Loss:0.303091   Training Accuracy:0.929688   Test Accuracy:0.906100\n",
      "Iteration:2200   Loss:0.262377   Training Accuracy:0.929688   Test Accuracy:0.906000\n",
      "Iteration:2250   Loss:0.239513   Training Accuracy:0.929688   Test Accuracy:0.905900\n",
      "Iteration:2300   Loss:0.322163   Training Accuracy:0.867188   Test Accuracy:0.905200\n",
      "Iteration:2350   Loss:0.314938   Training Accuracy:0.894531   Test Accuracy:0.906500\n",
      "Iteration:2400   Loss:0.393219   Training Accuracy:0.890625   Test Accuracy:0.907300\n",
      "Iteration:2450   Loss:0.328573   Training Accuracy:0.914062   Test Accuracy:0.908600\n",
      "Iteration:2500   Loss:0.328939   Training Accuracy:0.898438   Test Accuracy:0.910900\n",
      "Iteration:2550   Loss:0.241541   Training Accuracy:0.933594   Test Accuracy:0.908900\n",
      "Iteration:2600   Loss:0.230266   Training Accuracy:0.921875   Test Accuracy:0.908600\n",
      "Iteration:2650   Loss:0.255906   Training Accuracy:0.917969   Test Accuracy:0.910600\n",
      "Iteration:2700   Loss:0.329221   Training Accuracy:0.917969   Test Accuracy:0.908000\n",
      "Iteration:2750   Loss:0.309764   Training Accuracy:0.890625   Test Accuracy:0.910100\n",
      "Iteration:2800   Loss:0.249061   Training Accuracy:0.921875   Test Accuracy:0.912600\n",
      "Iteration:2850   Loss:0.313610   Training Accuracy:0.910156   Test Accuracy:0.910500\n",
      "Iteration:2900   Loss:0.251996   Training Accuracy:0.902344   Test Accuracy:0.910100\n",
      "Iteration:2950   Loss:0.267998   Training Accuracy:0.929688   Test Accuracy:0.907700\n",
      "Iteration:3000   Loss:0.400138   Training Accuracy:0.914062   Test Accuracy:0.909500\n",
      "Iteration:3050   Loss:0.244699   Training Accuracy:0.945312   Test Accuracy:0.909500\n",
      "Iteration:3100   Loss:0.225805   Training Accuracy:0.929688   Test Accuracy:0.913000\n",
      "Iteration:3150   Loss:0.296661   Training Accuracy:0.929688   Test Accuracy:0.914100\n",
      "Iteration:3200   Loss:0.322972   Training Accuracy:0.898438   Test Accuracy:0.912800\n",
      "Iteration:3250   Loss:0.234335   Training Accuracy:0.921875   Test Accuracy:0.914900\n",
      "Iteration:3300   Loss:0.285105   Training Accuracy:0.906250   Test Accuracy:0.913900\n",
      "Iteration:3350   Loss:0.362611   Training Accuracy:0.906250   Test Accuracy:0.912800\n",
      "Iteration:3400   Loss:0.295875   Training Accuracy:0.914062   Test Accuracy:0.914500\n",
      "Iteration:3450   Loss:0.344775   Training Accuracy:0.894531   Test Accuracy:0.915100\n",
      "Iteration:3500   Loss:0.284061   Training Accuracy:0.914062   Test Accuracy:0.912600\n",
      "Iteration:3550   Loss:0.326483   Training Accuracy:0.914062   Test Accuracy:0.914800\n",
      "Iteration:3600   Loss:0.277773   Training Accuracy:0.917969   Test Accuracy:0.913700\n",
      "Iteration:3650   Loss:0.312062   Training Accuracy:0.917969   Test Accuracy:0.915300\n",
      "Iteration:3700   Loss:0.319749   Training Accuracy:0.914062   Test Accuracy:0.914000\n",
      "Iteration:3750   Loss:0.330607   Training Accuracy:0.902344   Test Accuracy:0.914700\n",
      "Iteration:3800   Loss:0.265091   Training Accuracy:0.925781   Test Accuracy:0.916200\n",
      "Iteration:3850   Loss:0.337401   Training Accuracy:0.910156   Test Accuracy:0.916200\n",
      "Iteration:3900   Loss:0.212110   Training Accuracy:0.941406   Test Accuracy:0.917100\n",
      "Iteration:3950   Loss:0.263990   Training Accuracy:0.929688   Test Accuracy:0.912900\n",
      "Iteration:4000   Loss:0.298974   Training Accuracy:0.898438   Test Accuracy:0.915300\n",
      "Iteration:4050   Loss:0.257723   Training Accuracy:0.941406   Test Accuracy:0.916000\n",
      "Iteration:4100   Loss:0.233696   Training Accuracy:0.941406   Test Accuracy:0.917500\n",
      "Iteration:4150   Loss:0.208428   Training Accuracy:0.949219   Test Accuracy:0.917100\n",
      "Iteration:4200   Loss:0.171456   Training Accuracy:0.960938   Test Accuracy:0.919100\n",
      "Iteration:4250   Loss:0.295054   Training Accuracy:0.902344   Test Accuracy:0.918100\n",
      "Iteration:4300   Loss:0.325820   Training Accuracy:0.914062   Test Accuracy:0.919400\n",
      "Iteration:4350   Loss:0.266525   Training Accuracy:0.921875   Test Accuracy:0.918000\n",
      "Iteration:4400   Loss:0.258988   Training Accuracy:0.914062   Test Accuracy:0.917800\n",
      "Iteration:4450   Loss:0.218781   Training Accuracy:0.941406   Test Accuracy:0.916700\n",
      "Iteration:4500   Loss:0.300859   Training Accuracy:0.914062   Test Accuracy:0.919200\n",
      "Iteration:4550   Loss:0.306921   Training Accuracy:0.894531   Test Accuracy:0.919700\n",
      "Iteration:4600   Loss:0.397225   Training Accuracy:0.894531   Test Accuracy:0.921600\n",
      "Iteration:4650   Loss:0.277500   Training Accuracy:0.929688   Test Accuracy:0.919400\n",
      "Iteration:4700   Loss:0.380504   Training Accuracy:0.906250   Test Accuracy:0.921400\n",
      "Iteration:4750   Loss:0.234736   Training Accuracy:0.933594   Test Accuracy:0.920000\n",
      "Iteration:4800   Loss:0.353215   Training Accuracy:0.906250   Test Accuracy:0.920900\n",
      "Iteration:4850   Loss:0.252426   Training Accuracy:0.914062   Test Accuracy:0.918200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:4900   Loss:0.283135   Training Accuracy:0.898438   Test Accuracy:0.920700\n",
      "Iteration:4950   Loss:0.322200   Training Accuracy:0.921875   Test Accuracy:0.919100\n",
      "Iteration:5000   Loss:0.294663   Training Accuracy:0.917969   Test Accuracy:0.917200\n"
     ]
    }
   ],
   "source": [
    "max_iters = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "student_model = L.Classifier(studentNet())\n",
    "optimizer = optimizers.MomentumSGD(lr = learning_rate)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(student_model)\n",
    "\n",
    "train_model(student_model, optimizer, train_iter, test_iter, max_iters, out_dir, 'student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:50   Loss:0.685229   Training Accuracy:0.824219   Test Accuracy:0.835000\n",
      "Iteration:100   Loss:0.389298   Training Accuracy:0.921875   Test Accuracy:0.889000\n",
      "Iteration:150   Loss:0.326656   Training Accuracy:0.917969   Test Accuracy:0.904400\n",
      "Iteration:200   Loss:0.433185   Training Accuracy:0.875000   Test Accuracy:0.912000\n",
      "Iteration:250   Loss:0.303346   Training Accuracy:0.898438   Test Accuracy:0.916200\n",
      "Iteration:300   Loss:0.228991   Training Accuracy:0.929688   Test Accuracy:0.921800\n",
      "Iteration:350   Loss:0.199077   Training Accuracy:0.949219   Test Accuracy:0.927700\n",
      "Iteration:400   Loss:0.247275   Training Accuracy:0.925781   Test Accuracy:0.932300\n",
      "Iteration:450   Loss:0.262147   Training Accuracy:0.925781   Test Accuracy:0.937000\n",
      "Iteration:500   Loss:0.227333   Training Accuracy:0.917969   Test Accuracy:0.937000\n",
      "Iteration:550   Loss:0.250322   Training Accuracy:0.953125   Test Accuracy:0.940400\n",
      "Iteration:600   Loss:0.253789   Training Accuracy:0.937500   Test Accuracy:0.941600\n",
      "Iteration:650   Loss:0.200828   Training Accuracy:0.945312   Test Accuracy:0.944400\n",
      "Iteration:700   Loss:0.191271   Training Accuracy:0.953125   Test Accuracy:0.945800\n",
      "Iteration:750   Loss:0.176543   Training Accuracy:0.953125   Test Accuracy:0.947200\n",
      "Iteration:800   Loss:0.154214   Training Accuracy:0.949219   Test Accuracy:0.949400\n",
      "Iteration:850   Loss:0.178848   Training Accuracy:0.937500   Test Accuracy:0.952100\n",
      "Iteration:900   Loss:0.163617   Training Accuracy:0.945312   Test Accuracy:0.953500\n",
      "Iteration:950   Loss:0.169065   Training Accuracy:0.945312   Test Accuracy:0.953900\n",
      "Iteration:1000   Loss:0.112867   Training Accuracy:0.984375   Test Accuracy:0.954300\n",
      "Iteration:1050   Loss:0.182874   Training Accuracy:0.937500   Test Accuracy:0.953100\n",
      "Iteration:1100   Loss:0.195910   Training Accuracy:0.957031   Test Accuracy:0.957000\n",
      "Iteration:1150   Loss:0.110575   Training Accuracy:0.960938   Test Accuracy:0.959100\n",
      "Iteration:1200   Loss:0.119417   Training Accuracy:0.972656   Test Accuracy:0.960500\n",
      "Iteration:1250   Loss:0.152712   Training Accuracy:0.957031   Test Accuracy:0.958600\n",
      "Iteration:1300   Loss:0.083485   Training Accuracy:0.972656   Test Accuracy:0.961500\n",
      "Iteration:1350   Loss:0.125506   Training Accuracy:0.968750   Test Accuracy:0.961200\n",
      "Iteration:1400   Loss:0.120487   Training Accuracy:0.968750   Test Accuracy:0.964100\n",
      "Iteration:1450   Loss:0.129589   Training Accuracy:0.949219   Test Accuracy:0.960000\n",
      "Iteration:1500   Loss:0.136443   Training Accuracy:0.964844   Test Accuracy:0.964400\n",
      "Iteration:1550   Loss:0.105750   Training Accuracy:0.976562   Test Accuracy:0.965800\n",
      "Iteration:1600   Loss:0.103201   Training Accuracy:0.968750   Test Accuracy:0.965200\n",
      "Iteration:1650   Loss:0.096741   Training Accuracy:0.968750   Test Accuracy:0.967300\n",
      "Iteration:1700   Loss:0.088440   Training Accuracy:0.972656   Test Accuracy:0.966400\n",
      "Iteration:1750   Loss:0.090358   Training Accuracy:0.976562   Test Accuracy:0.967600\n",
      "Iteration:1800   Loss:0.099381   Training Accuracy:0.957031   Test Accuracy:0.968200\n",
      "Iteration:1850   Loss:0.103483   Training Accuracy:0.980469   Test Accuracy:0.968300\n",
      "Iteration:1900   Loss:0.068304   Training Accuracy:0.984375   Test Accuracy:0.968700\n",
      "Iteration:1950   Loss:0.081852   Training Accuracy:0.980469   Test Accuracy:0.969700\n",
      "Iteration:2000   Loss:0.094425   Training Accuracy:0.988281   Test Accuracy:0.969000\n",
      "Iteration:2050   Loss:0.078608   Training Accuracy:0.984375   Test Accuracy:0.969900\n",
      "Iteration:2100   Loss:0.080882   Training Accuracy:0.968750   Test Accuracy:0.969300\n",
      "Iteration:2150   Loss:0.126983   Training Accuracy:0.964844   Test Accuracy:0.970900\n",
      "Iteration:2200   Loss:0.091046   Training Accuracy:0.976562   Test Accuracy:0.970900\n",
      "Iteration:2250   Loss:0.065645   Training Accuracy:0.976562   Test Accuracy:0.972100\n",
      "Iteration:2300   Loss:0.092007   Training Accuracy:0.980469   Test Accuracy:0.970900\n",
      "Iteration:2350   Loss:0.116932   Training Accuracy:0.976562   Test Accuracy:0.972900\n",
      "Iteration:2400   Loss:0.095734   Training Accuracy:0.980469   Test Accuracy:0.972100\n",
      "Iteration:2450   Loss:0.126990   Training Accuracy:0.968750   Test Accuracy:0.973200\n",
      "Iteration:2500   Loss:0.068691   Training Accuracy:0.984375   Test Accuracy:0.972600\n",
      "Iteration:2550   Loss:0.050390   Training Accuracy:0.984375   Test Accuracy:0.974000\n",
      "Iteration:2600   Loss:0.084580   Training Accuracy:0.976562   Test Accuracy:0.973800\n",
      "Iteration:2650   Loss:0.047715   Training Accuracy:0.992188   Test Accuracy:0.973700\n",
      "Iteration:2700   Loss:0.053540   Training Accuracy:0.984375   Test Accuracy:0.974800\n",
      "Iteration:2750   Loss:0.052169   Training Accuracy:0.988281   Test Accuracy:0.974700\n",
      "Iteration:2800   Loss:0.071368   Training Accuracy:0.968750   Test Accuracy:0.974400\n",
      "Iteration:2850   Loss:0.029185   Training Accuracy:0.996094   Test Accuracy:0.975100\n",
      "Iteration:2900   Loss:0.078189   Training Accuracy:0.976562   Test Accuracy:0.975000\n",
      "Iteration:2950   Loss:0.030206   Training Accuracy:1.000000   Test Accuracy:0.975200\n",
      "Iteration:3000   Loss:0.067581   Training Accuracy:0.988281   Test Accuracy:0.974500\n",
      "Iteration:3050   Loss:0.044583   Training Accuracy:0.996094   Test Accuracy:0.974600\n",
      "Iteration:3100   Loss:0.055990   Training Accuracy:0.976562   Test Accuracy:0.975000\n",
      "Iteration:3150   Loss:0.052647   Training Accuracy:0.992188   Test Accuracy:0.975000\n",
      "Iteration:3200   Loss:0.045412   Training Accuracy:0.988281   Test Accuracy:0.974700\n",
      "Iteration:3250   Loss:0.076332   Training Accuracy:0.976562   Test Accuracy:0.974700\n",
      "Iteration:3300   Loss:0.031058   Training Accuracy:0.992188   Test Accuracy:0.975200\n",
      "Iteration:3350   Loss:0.058628   Training Accuracy:0.988281   Test Accuracy:0.975800\n",
      "Iteration:3400   Loss:0.037967   Training Accuracy:0.992188   Test Accuracy:0.976300\n",
      "Iteration:3450   Loss:0.045648   Training Accuracy:0.988281   Test Accuracy:0.976000\n",
      "Iteration:3500   Loss:0.038715   Training Accuracy:0.988281   Test Accuracy:0.976200\n",
      "Iteration:3550   Loss:0.052562   Training Accuracy:0.980469   Test Accuracy:0.976500\n",
      "Iteration:3600   Loss:0.044881   Training Accuracy:0.988281   Test Accuracy:0.976800\n",
      "Iteration:3650   Loss:0.039800   Training Accuracy:0.996094   Test Accuracy:0.976600\n",
      "Iteration:3700   Loss:0.060533   Training Accuracy:0.988281   Test Accuracy:0.975200\n",
      "Iteration:3750   Loss:0.043013   Training Accuracy:0.988281   Test Accuracy:0.976300\n",
      "Iteration:3800   Loss:0.049759   Training Accuracy:0.996094   Test Accuracy:0.975500\n",
      "Iteration:3850   Loss:0.058091   Training Accuracy:0.980469   Test Accuracy:0.976400\n",
      "Iteration:3900   Loss:0.045914   Training Accuracy:0.992188   Test Accuracy:0.976500\n",
      "Iteration:3950   Loss:0.040343   Training Accuracy:0.988281   Test Accuracy:0.976900\n",
      "Iteration:4000   Loss:0.053627   Training Accuracy:0.980469   Test Accuracy:0.976100\n",
      "Iteration:4050   Loss:0.055050   Training Accuracy:0.992188   Test Accuracy:0.977300\n",
      "Iteration:4100   Loss:0.047200   Training Accuracy:0.980469   Test Accuracy:0.976900\n",
      "Iteration:4150   Loss:0.051124   Training Accuracy:0.988281   Test Accuracy:0.976800\n",
      "Iteration:4200   Loss:0.063297   Training Accuracy:0.992188   Test Accuracy:0.977100\n",
      "Iteration:4250   Loss:0.035995   Training Accuracy:0.996094   Test Accuracy:0.977200\n",
      "Iteration:4300   Loss:0.035628   Training Accuracy:0.984375   Test Accuracy:0.976900\n",
      "Iteration:4350   Loss:0.050105   Training Accuracy:0.980469   Test Accuracy:0.976900\n",
      "Iteration:4400   Loss:0.037152   Training Accuracy:0.984375   Test Accuracy:0.977200\n",
      "Iteration:4450   Loss:0.036638   Training Accuracy:0.996094   Test Accuracy:0.976900\n",
      "Iteration:4500   Loss:0.064374   Training Accuracy:0.984375   Test Accuracy:0.977400\n",
      "Iteration:4550   Loss:0.071200   Training Accuracy:0.972656   Test Accuracy:0.977600\n",
      "Iteration:4600   Loss:0.048442   Training Accuracy:0.988281   Test Accuracy:0.977200\n",
      "Iteration:4650   Loss:0.022442   Training Accuracy:0.996094   Test Accuracy:0.977000\n",
      "Iteration:4700   Loss:0.040406   Training Accuracy:0.992188   Test Accuracy:0.977400\n",
      "Iteration:4750   Loss:0.030650   Training Accuracy:0.988281   Test Accuracy:0.977000\n",
      "Iteration:4800   Loss:0.076252   Training Accuracy:0.968750   Test Accuracy:0.977400\n",
      "Iteration:4850   Loss:0.066418   Training Accuracy:0.976562   Test Accuracy:0.978200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:4900   Loss:0.032623   Training Accuracy:0.992188   Test Accuracy:0.977700\n",
      "Iteration:4950   Loss:0.033515   Training Accuracy:0.988281   Test Accuracy:0.978000\n",
      "Iteration:5000   Loss:0.025658   Training Accuracy:0.996094   Test Accuracy:0.977700\n"
     ]
    }
   ],
   "source": [
    "max_iters = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "teacher_model = L.Classifier(teacherNet())\n",
    "optimizer = optimizers.MomentumSGD(lr = learning_rate)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(teacher_model)\n",
    "\n",
    "train_model(teacher_model, optimizer, train_iter, test_iter, max_iters, out_dir, 'teacher')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distill dark knowledge from teacher model and train student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:50   Loss:1.851699   Training Accuracy:0.417969   Test Accuracy:0.454000\n",
      "Iteration:100   Loss:1.389670   Training Accuracy:0.597656   Test Accuracy:0.634900\n",
      "Iteration:150   Loss:0.900136   Training Accuracy:0.757812   Test Accuracy:0.737100\n",
      "Iteration:200   Loss:0.668745   Training Accuracy:0.812500   Test Accuracy:0.809400\n",
      "Iteration:250   Loss:0.634422   Training Accuracy:0.828125   Test Accuracy:0.838700\n",
      "Iteration:300   Loss:0.492543   Training Accuracy:0.859375   Test Accuracy:0.852800\n",
      "Iteration:350   Loss:0.478407   Training Accuracy:0.867188   Test Accuracy:0.867100\n",
      "Iteration:400   Loss:0.367337   Training Accuracy:0.867188   Test Accuracy:0.867300\n",
      "Iteration:450   Loss:0.469983   Training Accuracy:0.890625   Test Accuracy:0.880600\n",
      "Iteration:500   Loss:0.410960   Training Accuracy:0.875000   Test Accuracy:0.883500\n",
      "Iteration:550   Loss:0.433901   Training Accuracy:0.867188   Test Accuracy:0.888000\n",
      "Iteration:600   Loss:0.378107   Training Accuracy:0.910156   Test Accuracy:0.893200\n",
      "Iteration:650   Loss:0.371253   Training Accuracy:0.890625   Test Accuracy:0.896700\n",
      "Iteration:700   Loss:0.341436   Training Accuracy:0.906250   Test Accuracy:0.897200\n",
      "Iteration:750   Loss:0.345989   Training Accuracy:0.894531   Test Accuracy:0.898400\n",
      "Iteration:800   Loss:0.277488   Training Accuracy:0.945312   Test Accuracy:0.902600\n",
      "Iteration:850   Loss:0.424594   Training Accuracy:0.871094   Test Accuracy:0.902000\n",
      "Iteration:900   Loss:0.360004   Training Accuracy:0.902344   Test Accuracy:0.903700\n",
      "Iteration:950   Loss:0.350896   Training Accuracy:0.886719   Test Accuracy:0.906600\n",
      "Iteration:1000   Loss:0.285967   Training Accuracy:0.921875   Test Accuracy:0.905400\n",
      "Iteration:1050   Loss:0.322589   Training Accuracy:0.898438   Test Accuracy:0.907600\n",
      "Iteration:1100   Loss:0.299024   Training Accuracy:0.914062   Test Accuracy:0.905400\n",
      "Iteration:1150   Loss:0.340019   Training Accuracy:0.886719   Test Accuracy:0.907000\n",
      "Iteration:1200   Loss:0.361097   Training Accuracy:0.902344   Test Accuracy:0.908000\n",
      "Iteration:1250   Loss:0.318477   Training Accuracy:0.902344   Test Accuracy:0.909100\n",
      "Iteration:1300   Loss:0.290593   Training Accuracy:0.894531   Test Accuracy:0.908100\n",
      "Iteration:1350   Loss:0.252846   Training Accuracy:0.937500   Test Accuracy:0.912000\n",
      "Iteration:1400   Loss:0.351390   Training Accuracy:0.921875   Test Accuracy:0.906800\n",
      "Iteration:1450   Loss:0.299376   Training Accuracy:0.902344   Test Accuracy:0.912400\n",
      "Iteration:1500   Loss:0.443692   Training Accuracy:0.886719   Test Accuracy:0.910700\n",
      "Iteration:1550   Loss:0.377684   Training Accuracy:0.902344   Test Accuracy:0.912700\n",
      "Iteration:1600   Loss:0.337467   Training Accuracy:0.925781   Test Accuracy:0.909400\n",
      "Iteration:1650   Loss:0.286785   Training Accuracy:0.917969   Test Accuracy:0.913900\n",
      "Iteration:1700   Loss:0.325620   Training Accuracy:0.882812   Test Accuracy:0.912400\n",
      "Iteration:1750   Loss:0.299111   Training Accuracy:0.917969   Test Accuracy:0.914900\n",
      "Iteration:1800   Loss:0.285789   Training Accuracy:0.906250   Test Accuracy:0.914700\n",
      "Iteration:1850   Loss:0.325369   Training Accuracy:0.910156   Test Accuracy:0.915700\n",
      "Iteration:1900   Loss:0.256623   Training Accuracy:0.933594   Test Accuracy:0.915300\n",
      "Iteration:1950   Loss:0.334253   Training Accuracy:0.886719   Test Accuracy:0.916300\n",
      "Iteration:2000   Loss:0.234428   Training Accuracy:0.941406   Test Accuracy:0.916000\n",
      "Iteration:2050   Loss:0.266901   Training Accuracy:0.933594   Test Accuracy:0.913900\n",
      "Iteration:2100   Loss:0.248112   Training Accuracy:0.914062   Test Accuracy:0.917500\n",
      "Iteration:2150   Loss:0.242645   Training Accuracy:0.929688   Test Accuracy:0.919900\n",
      "Iteration:2200   Loss:0.293847   Training Accuracy:0.925781   Test Accuracy:0.919700\n",
      "Iteration:2250   Loss:0.238582   Training Accuracy:0.929688   Test Accuracy:0.917000\n",
      "Iteration:2300   Loss:0.237867   Training Accuracy:0.949219   Test Accuracy:0.918500\n",
      "Iteration:2350   Loss:0.373737   Training Accuracy:0.894531   Test Accuracy:0.919500\n",
      "Iteration:2400   Loss:0.254878   Training Accuracy:0.929688   Test Accuracy:0.918300\n",
      "Iteration:2450   Loss:0.214395   Training Accuracy:0.941406   Test Accuracy:0.919100\n",
      "Iteration:2500   Loss:0.238819   Training Accuracy:0.917969   Test Accuracy:0.920500\n",
      "Iteration:2550   Loss:0.250281   Training Accuracy:0.929688   Test Accuracy:0.921300\n",
      "Iteration:2600   Loss:0.273559   Training Accuracy:0.910156   Test Accuracy:0.922300\n",
      "Iteration:2650   Loss:0.175611   Training Accuracy:0.960938   Test Accuracy:0.922100\n",
      "Iteration:2700   Loss:0.261384   Training Accuracy:0.921875   Test Accuracy:0.921700\n",
      "Iteration:2750   Loss:0.242891   Training Accuracy:0.917969   Test Accuracy:0.923000\n",
      "Iteration:2800   Loss:0.225860   Training Accuracy:0.937500   Test Accuracy:0.922500\n",
      "Iteration:2850   Loss:0.275247   Training Accuracy:0.917969   Test Accuracy:0.923000\n",
      "Iteration:2900   Loss:0.253593   Training Accuracy:0.933594   Test Accuracy:0.924900\n",
      "Iteration:2950   Loss:0.248633   Training Accuracy:0.914062   Test Accuracy:0.922100\n",
      "Iteration:3000   Loss:0.194462   Training Accuracy:0.941406   Test Accuracy:0.919500\n",
      "Iteration:3050   Loss:0.280009   Training Accuracy:0.906250   Test Accuracy:0.923300\n",
      "Iteration:3100   Loss:0.286532   Training Accuracy:0.929688   Test Accuracy:0.921700\n",
      "Iteration:3150   Loss:0.218354   Training Accuracy:0.937500   Test Accuracy:0.924000\n",
      "Iteration:3200   Loss:0.211698   Training Accuracy:0.937500   Test Accuracy:0.924300\n",
      "Iteration:3250   Loss:0.252066   Training Accuracy:0.921875   Test Accuracy:0.923500\n",
      "Iteration:3300   Loss:0.192014   Training Accuracy:0.933594   Test Accuracy:0.924500\n",
      "Iteration:3350   Loss:0.242781   Training Accuracy:0.921875   Test Accuracy:0.924500\n",
      "Iteration:3400   Loss:0.238246   Training Accuracy:0.925781   Test Accuracy:0.923200\n",
      "Iteration:3450   Loss:0.216600   Training Accuracy:0.957031   Test Accuracy:0.925700\n",
      "Iteration:3500   Loss:0.237323   Training Accuracy:0.925781   Test Accuracy:0.924300\n",
      "Iteration:3550   Loss:0.305724   Training Accuracy:0.910156   Test Accuracy:0.926600\n",
      "Iteration:3600   Loss:0.202317   Training Accuracy:0.933594   Test Accuracy:0.924500\n",
      "Iteration:3650   Loss:0.362476   Training Accuracy:0.910156   Test Accuracy:0.924100\n",
      "Iteration:3700   Loss:0.296401   Training Accuracy:0.894531   Test Accuracy:0.921500\n",
      "Iteration:3750   Loss:0.324714   Training Accuracy:0.894531   Test Accuracy:0.924900\n",
      "Iteration:3800   Loss:0.281944   Training Accuracy:0.933594   Test Accuracy:0.924000\n",
      "Iteration:3850   Loss:0.325429   Training Accuracy:0.886719   Test Accuracy:0.923500\n",
      "Iteration:3900   Loss:0.217381   Training Accuracy:0.945312   Test Accuracy:0.926400\n",
      "Iteration:3950   Loss:0.258683   Training Accuracy:0.910156   Test Accuracy:0.925200\n",
      "Iteration:4000   Loss:0.257087   Training Accuracy:0.925781   Test Accuracy:0.926000\n",
      "Iteration:4050   Loss:0.231505   Training Accuracy:0.937500   Test Accuracy:0.926500\n",
      "Iteration:4100   Loss:0.206707   Training Accuracy:0.941406   Test Accuracy:0.926500\n",
      "Iteration:4150   Loss:0.145693   Training Accuracy:0.960938   Test Accuracy:0.927300\n",
      "Iteration:4200   Loss:0.255080   Training Accuracy:0.925781   Test Accuracy:0.926000\n",
      "Iteration:4250   Loss:0.315932   Training Accuracy:0.890625   Test Accuracy:0.925600\n",
      "Iteration:4300   Loss:0.264307   Training Accuracy:0.917969   Test Accuracy:0.928000\n",
      "Iteration:4350   Loss:0.218962   Training Accuracy:0.929688   Test Accuracy:0.928000\n",
      "Iteration:4400   Loss:0.281484   Training Accuracy:0.917969   Test Accuracy:0.925700\n",
      "Iteration:4450   Loss:0.198700   Training Accuracy:0.937500   Test Accuracy:0.926000\n",
      "Iteration:4500   Loss:0.245778   Training Accuracy:0.929688   Test Accuracy:0.927900\n",
      "Iteration:4550   Loss:0.243145   Training Accuracy:0.921875   Test Accuracy:0.927300\n",
      "Iteration:4600   Loss:0.203674   Training Accuracy:0.921875   Test Accuracy:0.925000\n",
      "Iteration:4650   Loss:0.246654   Training Accuracy:0.910156   Test Accuracy:0.924800\n",
      "Iteration:4700   Loss:0.225484   Training Accuracy:0.921875   Test Accuracy:0.926300\n",
      "Iteration:4750   Loss:0.177622   Training Accuracy:0.933594   Test Accuracy:0.925700\n",
      "Iteration:4800   Loss:0.207103   Training Accuracy:0.937500   Test Accuracy:0.926300\n",
      "Iteration:4850   Loss:0.258257   Training Accuracy:0.933594   Test Accuracy:0.926700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:4900   Loss:0.219951   Training Accuracy:0.921875   Test Accuracy:0.928600\n",
      "Iteration:4950   Loss:0.208631   Training Accuracy:0.945312   Test Accuracy:0.928400\n",
      "Iteration:5000   Loss:0.297335   Training Accuracy:0.914062   Test Accuracy:0.925600\n"
     ]
    }
   ],
   "source": [
    "max_iters = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# create student model\n",
    "student = studentNet()\n",
    "student.train = True\n",
    "# load teacher model\n",
    "teacher = teacherNet()\n",
    "serializers.load_hdf5(os.path.join(out_dir,'teacher.model'), teacher)\n",
    "teacher.train = False\n",
    "teacher.to_gpu()\n",
    "distiller = DistillPredictor(teacher, student, T = 1.0, alpha = 0.7)\n",
    "optimizer = optimizers.MomentumSGD(lr = learning_rate)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(distiller)\n",
    "\n",
    "train_model(distiller, optimizer, train_iter, test_iter, max_iters, out_dir, 'distill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7de894ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_list = ['student', 'teacher', 'distill']\n",
    "acc_list = []\n",
    "for log_name in log_list:\n",
    "    log_file = sorted(glob.glob(os.path.join(out_dir, log_name + '*.csv')))[-1]\n",
    "    with open(log_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    test_acc = [float(line.split(',')[-1]) for line in lines]\n",
    "    iter = [float(line.split(',')[0]) for line in lines]\n",
    "    acc_list.append(test_acc)\n",
    "    plt.plot(iter, test_acc, label = log_name)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
